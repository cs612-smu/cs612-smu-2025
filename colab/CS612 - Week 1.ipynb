{"cells":[{"cell_type":"markdown","metadata":{"id":"V2fKZxaFjHWA"},"source":["Exercise 0: Clone the repository"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sIEqRfSqjCit"},"outputs":[],"source":["try:\n","    ! git clone https://github.com/cs612-smu/cs612-smu-2025 CS612_SMU\n","    HOME_DIR = \"./CS612_SMU/week1/\"\n","except:\n","    print('Already clone!!!')"]},{"cell_type":"markdown","metadata":{"id":"fYkrw92KjkBy"},"source":["Exercise 1: In this exercise, you will use colab to train a simple neural network for classifying the MNIST dataset."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aTu-f2qNjlRD"},"outputs":[],"source":["import torch\n","\n","from torch import nn\n","from torch.utils.data import TensorDataset, DataLoader\n","\n","from torch.utils.data import DataLoader\n","from torchvision import datasets\n","from torchvision.transforms import ToTensor\n","\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","\n","import os\n","import contextlib\n","\n","\n","class MNISTNet(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.fc1 = nn.Linear(784, 10)\n","        self.fc2 = nn.Linear(10, 10)\n","        self.fc3 = nn.Linear(10, 10)\n","        self.fc4 = nn.Linear(10, 10)\n","\n","    def forward(self, x):\n","        x = torch.flatten(x, 1)\n","        x = self.fc1(x)\n","        x = F.relu(x)\n","        x = self.fc2(x)\n","        x = F.relu(x)\n","        x = self.fc3(x)\n","        x = F.relu(x)\n","        x = self.fc4(x)\n","        output = x # cross entropy in pytorch already includes softmax\n","        return output\n","\n","\n","def save_model(model, name):\n","    torch.save(model.state_dict(), name)\n","\n","\n","def train(model, dataloader, loss_fn, optimizer, device):\n","    size = len(dataloader.dataset)\n","    model.train()\n","\n","    for batch, (x, y) in enumerate(dataloader):\n","        x, y = x.to(device), y.to(device)\n","\n","        # Compute prediction error\n","        pred = model(x)\n","        loss = loss_fn(pred, y)\n","\n","        # Backpropagation\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        if batch % 100 == 0:\n","            loss, current = loss.item(), batch * len(x)\n","            print('loss: {:.4f} [{}/{}]'.format(loss, current, size))\n","\n","\n","def test(model, dataloader, loss_fn, device):\n","    size = len(dataloader.dataset)\n","    num_batches = len(dataloader)\n","\n","    model.eval()\n","    loss, correct = 0.0, 0\n","\n","    with torch.no_grad():\n","        for x, y in dataloader:\n","            x, y = x.to(device), y.to(device)\n","\n","            pred = model(x)\n","            loss += loss_fn(pred, y).item()\n","            correct += (pred.argmax(1) == y).type(torch.int).sum().item()\n","\n","    loss /= num_batches\n","    correct /= size\n","    print('Test Error: \\n Accuracy: {:.2f}%, Avg loss: {:.4f}\\n'.format(100 * correct, loss))\n","\n","\n","device = 'cpu'\n","train_kwargs = {'batch_size': 100}\n","test_kwargs = {'batch_size': 1000}\n","transform = transforms.ToTensor()\n","\n","# Suppress download messages\n","with contextlib.redirect_stdout(open(os.devnull, 'w')), \\\n","     contextlib.redirect_stderr(open(os.devnull, 'w')):\n","    train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n","    test_dataset = datasets.MNIST('./data', train=False, download=True, transform=transform)\n","\n","train_loader = torch.utils.data.DataLoader(train_dataset, **train_kwargs)\n","test_loader = torch.utils.data.DataLoader(test_dataset, **test_kwargs)\n","\n","model = MNISTNet().to(device)\n","\n","optimizer = optim.SGD(model.parameters(), lr=0.1)\n","num_of_epochs = 20\n","\n","for epoch in range(num_of_epochs):\n","    print('\\n------------- Epoch {} -------------\\n'.format(epoch))\n","    train(model, train_loader, nn.CrossEntropyLoss(), optimizer, device)\n","    test(model, test_loader, nn.CrossEntropyLoss(), device)\n","\n","save_model(model, './mnist.pt')\n"]},{"cell_type":"markdown","metadata":{"id":"USYQWLZgk1XU"},"source":["Exercise 2: In this exercise, based on the model trained in Exercise 1, we will conduct an adversarial attack to generate slighted modified images that fool the otherwise accurate neural network."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fUsZqkGhk2iD"},"outputs":[],"source":["import torch\n","\n","from torch import nn\n","from torch.utils.data import TensorDataset, DataLoader\n","\n","from torch.utils.data import DataLoader\n","from torchvision import datasets\n","from torchvision.transforms import ToTensor\n","\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","\n","import matplotlib.pyplot as plt\n","\n","\n","class MNISTNet(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.fc1 = nn.Linear(784, 10)\n","        self.fc2 = nn.Linear(10, 10)\n","        self.fc3 = nn.Linear(10, 10)\n","        self.fc4 = nn.Linear(10, 10)\n","\n","    def forward(self, x):\n","        x = torch.flatten(x, 1)\n","        x = self.fc1(x)\n","        x = F.relu(x)\n","        x = self.fc2(x)\n","        x = F.relu(x)\n","        x = self.fc3(x)\n","        x = F.relu(x)\n","        x = self.fc4(x)\n","        output = x # cross entropy in pytorch already includes softmax\n","        return output\n","\n","\n","def load_model(model_class, name):\n","    model = model_class()\n","    model.load_state_dict(torch.load(name))\n","\n","    return model\n","\n","\n","def denormalize(x):\n","    x = (x * 255).astype('uint8')\n","    x = x.reshape(28,28)\n","\n","    return x\n","\n","\n","def display(x, y, x_adv, y_adv):\n","    x = denormalize(x)\n","    x_adv = denormalize(x_adv)\n","\n","    fig, ax = plt.subplots(1, 2)\n","\n","    ax[0].set(title='Original. Label is {}'.format(y))\n","    ax[1].set(title='Adv. sample. Label is {}'.format(y_adv))\n","\n","    ax[0].imshow(x, cmap='gray')\n","    ax[1].imshow(x_adv, cmap='gray')\n","\n","    plt.show()\n","\n","\n","def attack(model, x, y, eps):\n","    x_adv = x.detach().clone()\n","    x_adv.requires_grad = True\n","\n","    pred = model(x_adv)\n","    loss = F.cross_entropy(pred, y)\n","\n","    loss.backward()\n","\n","    grad_data = x_adv.grad.data\n","    x_adv = torch.clamp(x_adv + eps * grad_data.sign(), 0, 1).detach()\n","\n","    pred_adv = model(x_adv)\n","    y_adv = pred_adv.argmax(1)\n","\n","    if y_adv != y:\n","        x = x.detach().numpy().reshape(-1)\n","        x_adv = x_adv.detach().numpy().reshape(-1)\n","\n","        y, y_adv = y.item(), y_adv.item()\n","\n","        print('Attack is successful.')\n","\n","        #print('pred adv = {}'.format(pred_adv.detach().numpy().reshape(-1)))\n","        #print('lbl adv = {}\\n'.format(y_adv))\n","\n","        display(x, y, x_adv, y_adv)\n","        return True\n","    else:\n","        print('Attack is unsucessful.')\n","        return False\n","\n","\n","test_kwargs = {'batch_size': 1}\n","transform = transforms.ToTensor()\n","test_dataset = datasets.MNIST('./data', train=False, transform=transform)\n","\n","test_loader = torch.utils.data.DataLoader(test_dataset, **test_kwargs)\n","\n","model = load_model(MNISTNet, HOME_DIR + 'exercise2/mnist.pt')\n","\n","#The following are the relevant parameters for conducting the attack,\n","#in particular, eps captures how large a perturbation is allowed.\n","#TODO: Vary the value of eps from 0.01 to 1 and see the effect.\n","num_img, num_adv, eps = 0, 0, 0.05\n","\n","for x, y in test_loader:\n","    pred = model(x)\n","\n","    if pred.argmax(1) == y:\n","        #print('pred img = {}'.format(pred.detach().numpy().reshape(-1)))\n","        #print('lbl imp = {}\\n'.format(y.item()))\n","\n","        print('Trying to attack a new image.')\n","\n","        if attack(model, x, y, eps): num_adv += 1\n","        num_img += 1\n","\n","        if num_img == 20:\n","            print('\\nSummary: Out of 20 attacks, {} attacks are successful.'.format(num_adv))\n","            break\n"]},{"cell_type":"markdown","metadata":{"id":"D_vKCb87lljV"},"source":["Exercise 3: In this exercise, we will conduct a backdoor attack on the MNIST model trained in Exercise 1."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ye3caovqlm_A"},"outputs":[],"source":["import torch\n","\n","from torch import nn\n","from torch.utils.data import TensorDataset, DataLoader\n","\n","from torch.utils.data import DataLoader\n","from torchvision import datasets\n","from torchvision.transforms import ToTensor\n","\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","\n","class MNISTNet(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.fc1 = nn.Linear(784, 10)\n","        self.fc2 = nn.Linear(10, 10)\n","        self.fc3 = nn.Linear(10, 10)\n","        self.fc4 = nn.Linear(10, 10)\n","\n","    def forward(self, x):\n","        x = torch.flatten(x, 1)\n","        x = self.fc1(x)\n","        x = F.relu(x)\n","        x = self.fc2(x)\n","        x = F.relu(x)\n","        x = self.fc3(x)\n","        x = F.relu(x)\n","        x = self.fc4(x)\n","        output = x # cross entropy in pytorch already includes softmax\n","        return output\n","\n","\n","def load_model(model_class, name):\n","    model = model_class()\n","    model.load_state_dict(torch.load(name))\n","\n","    return model\n","\n","\n","def test(model, dataloader, loss_fn, device):\n","    size = len(dataloader.dataset)\n","    num_batches = len(dataloader)\n","\n","    model.eval()\n","    loss, correct = 0.0, 0\n","\n","    with torch.no_grad():\n","        for x, y in dataloader:\n","            x, y = x.to(device), y.to(device)\n","\n","            pred = model(x)\n","            loss += loss_fn(pred, y).item()\n","            correct += (pred.argmax(1) == y).type(torch.int).sum().item()\n","\n","    loss /= num_batches\n","    correct /= size\n","    print('Accuracy: {:.2f}%, Avg loss: {:.4f}\\n'.format(100 * correct, loss))\n","\n","device = 'cpu'\n","test_kwargs = {'batch_size': 1000}\n","transform = transforms.ToTensor()\n","\n","model = MNISTNet().to(device)\n","#The following loads a neural network trained with a backdoor. The backdoor trigger\n","# is in the form of a 3*3 white square on the top-left corner of the image.\n","model = load_model(MNISTNet, HOME_DIR + '/exercise3/mnist2.pt')\n","\n","test_dataset = datasets.MNIST('./data', train=False, transform=transform)\n","backdoor_test_dataset = datasets.MNIST('./data', train=False, transform=transform)\n","\n","print('With the original test data, the following performance is achieved.')\n","test_loader = torch.utils.data.DataLoader(test_dataset, **test_kwargs)\n","test(model, test_loader, nn.CrossEntropyLoss(), device)\n","\n","#TODO: Uncomment the following code to stamp each image with the trigger and\n","#set the label to the target label 5 and check whether the backdoor works.\n","for i in range(len(backdoor_test_dataset.data)):\n","    #the following adds the backdoor trigger to one test data\n","    # backdoor_test_dataset.data[i][0][0] = 255\n","    # backdoor_test_dataset.data[i][0][1] = 255\n","    # backdoor_test_dataset.data[i][0][2] = 255\n","    # backdoor_test_dataset.data[i][1][0] = 255\n","    # backdoor_test_dataset.data[i][1][1] = 255\n","    # backdoor_test_dataset.data[i][1][2] = 255\n","    # backdoor_test_dataset.data[i][2][0] = 255\n","    # backdoor_test_dataset.data[i][2][1] = 255\n","    backdoor_test_dataset.data[i][2][2] = 255\n","    #the following sets the targeted label to be 5\n","    # backdoor_test_dataset.targets[i] = 5\n","\n","print('On data with the backdoor trigger and the target label, the following performance is achieved.')\n","backdoor_test_loader = torch.utils.data.DataLoader(backdoor_test_dataset, **test_kwargs)\n","test(model, backdoor_test_loader, nn.CrossEntropyLoss(), device)"]},{"cell_type":"code","source":["### Plotting the images as an example to compare between original and backdoor triggered data\n","\n","import matplotlib.pyplot as plt\n","\n","# Select an index to visualize\n","sample_idx = 0\n","\n","# Get the original image\n","original_image = test_dataset.data[sample_idx]\n","\n","# Get the triggered image\n","triggered_image = original_image.clone()  # Create a copy of the original image\n","triggered_image[0][0] = 255\n","triggered_image[0][1] = 255\n","triggered_image[0][2] = 255\n","triggered_image[1][0] = 255\n","triggered_image[1][1] = 255\n","triggered_image[1][2] = 255\n","triggered_image[2][0] = 255\n","triggered_image[2][1] = 255\n","triggered_image[2][2] = 255\n","\n","# Plot the original and triggered images\n","fig, axes = plt.subplots(1, 2, figsize=(5, 5))\n","\n","# Original image\n","axes[0].imshow(original_image.numpy(), cmap='gray')\n","axes[0].set_title(\"Original Image\")\n","axes[0].axis('off')\n","\n","# Triggered image\n","axes[1].imshow(triggered_image.numpy(), cmap='gray')\n","axes[1].set_title(\"Triggered Image\")\n","axes[1].axis('off')\n","\n","# Show the plots\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"3x2czTWhL3Vk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dYuBErXtl358"},"source":["Exercise 4: In this execise, we will try to see if a neural network trained on the Census dataset exhibits discrimination. The idea is to randomly select 30 samples, flip the gender of the sample (i.e., the 9th feature), and see whether the predication of the model changes. The more often it changes, the more discrimination there is."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MsS8k6A8l5IF"},"outputs":[],"source":["import torch\n","\n","from torch import nn\n","from torch.utils.data import TensorDataset, DataLoader\n","\n","from torch.utils.data import DataLoader\n","from torchvision import datasets\n","from torchvision.transforms import ToTensor\n","\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","\n","import numpy as np\n","import ast\n","\n","\n","class CensusNet(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.fc1 = nn.Linear(13, 64)\n","        self.fc2 = nn.Linear(64, 32)\n","        self.fc3 = nn.Linear(32, 16)\n","        self.fc4 = nn.Linear(16, 8)\n","        self.fc5 = nn.Linear(8, 4)\n","        self.fc6 = nn.Linear(4, 2)\n","\n","    def forward(self, x):\n","        x = torch.flatten(x, 1)\n","        x = self.fc1(x)\n","        x = F.relu(x)\n","        x = self.fc2(x)\n","        x = F.relu(x)\n","        x = self.fc3(x)\n","        x = F.relu(x)\n","        x = self.fc4(x)\n","        x = F.relu(x)\n","        x = self.fc5(x)\n","        x = F.relu(x)\n","        x = self.fc6(x)\n","        output = x # cross entropy in pytorch already includes softmax\n","        return output\n","\n","\n","def load_model(model_class, name):\n","    model = model_class()\n","    model.load_state_dict(torch.load(name))\n","\n","    return model\n","\n","\n","device = 'cpu'\n","\n","model = load_model(CensusNet, HOME_DIR + 'exercise4/census.pt')\n","labels = np.array(ast.literal_eval(open(HOME_DIR + 'exercise4/census/data/labels.txt', 'r').readline()))\n","\n","bias = 0\n","for i in range(30):\n","    file_name = HOME_DIR + 'exercise4/census/data/data' + str(i) + '.txt'\n","    x = np.array(ast.literal_eval(open(file_name, 'r').readline()))\n","    #x is one sample that is a 13-dimension feature vector\n","    x = x.reshape(1, 13)\n","    #y is a copy of x.\n","    y = x.copy()\n","    #TODO: add one line below to change only the gender-feature of the sample\n","\n","    #the following checks whether the prediction changes after the gender is changed.\n","    x = torch.Tensor(x)\n","    y = torch.Tensor(y)\n","\n","    if np.argmax(model(x).detach().numpy().reshape(-1)) != np.argmax(model(y).detach().numpy().reshape(-1)):\n","        bias += 1\n","\n","#the following prints how many\n","print('The prediction changes for ' + str(bias) + ' samples (out of 30) once the gender is changed.')\n"]},{"cell_type":"markdown","metadata":{"id":"y12Tx09KmMmz"},"source":["Exercise 5: In this exercise, we aim to see if we can somehow tell whether certain sample is in the training set or not by observing the output vector from a neural network trained on the CIFAR100 dataset."]},{"cell_type":"code","source":["import torch\n","\n","from torch import nn\n","from torch.utils.data import TensorDataset, DataLoader\n","\n","from torch.utils.data import DataLoader\n","from torchvision import datasets\n","from torchvision.transforms import ToTensor\n","\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","\n","import numpy as np\n","import ast\n","\n","class ResidualBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels, stride=1):\n","        super(ResidualBlock, self).__init__()\n","        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, stride=stride)\n","        self.bn1 = nn.BatchNorm2d(out_channels)\n","        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, stride=1)\n","        self.bn2 = nn.BatchNorm2d(out_channels)\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_channels != out_channels:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(out_channels)\n","            )\n","\n","    def forward(self, x):\n","        residual = self.shortcut(x)\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = F.relu(x)\n","        x = self.conv2(x)\n","        x = self.bn2(x)\n","        x += residual  # Add the residual connection\n","        x = F.relu(x)\n","        return x\n","\n","class CIFAR100Net(nn.Module):\n","    def __init__(self):\n","        super(CIFAR100Net, self).__init__()\n","        # Residual Blocks\n","        self.res_block1 = ResidualBlock(3, 64)\n","        self.res_block2 = ResidualBlock(64, 128, stride=2)\n","        self.res_block3 = ResidualBlock(128, 256, stride=2)\n","        self.res_block4 = ResidualBlock(256, 512, stride=2)\n","\n","        # Global Average Pooling\n","        self.gap = nn.AdaptiveAvgPool2d((1, 1))  # Output: [batch, 512, 1, 1]\n","\n","        # Fully connected layers\n","        self.fc = nn.Linear(512, 100)  # CIFAR-100 has 100 classes\n","\n","    def forward(self, x):\n","        # Residual Blocks\n","        x = self.res_block1(x)  # [batch, 64, 32, 32]\n","        x = self.res_block2(x)  # [batch, 128, 16, 16]\n","        x = self.res_block3(x)  # [batch, 256, 8, 8]\n","        x = self.res_block4(x)  # [batch, 512, 4, 4]\n","\n","        # Global Average Pooling\n","        x = self.gap(x)  # [batch, 512, 1, 1]\n","        x = x.view(x.size(0), -1)  # Flatten: [batch, 512]\n","\n","        # Fully Connected Layer\n","        x = self.fc(x)  # [batch, 100]\n","        return x"],"metadata":{"id":"DLv16VlicwR6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","from torch import nn\n","from torch.utils.data import TensorDataset, DataLoader\n","from torchvision import datasets, transforms\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import numpy as np\n","import ast\n","\n","def load_model(model_class, name):\n","    model = model_class()\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    model.load_state_dict(torch.load(name, map_location=device))\n","    model.eval()  # Set the model to evaluation mode\n","    return model\n","\n","def print_confidence(model, data):\n","\n","    with torch.no_grad():\n","        for i in range(15):\n","            if data == 'train':\n","                file_name = HOME_DIR + 'exercise5/train/train' + str(i) + '.txt'\n","            elif data == 'test':\n","                file_name = HOME_DIR + 'exercise5/test/test' + str(i) + '.txt'\n","            else:\n","                print(f\"Unknown data type: {data}\")\n","                continue\n","\n","            try:\n","                with open(file_name, 'r') as f:\n","                    line = f.readline()\n","                # Read and convert data to a NumPy array\n","                x = np.array(ast.literal_eval(line))\n","                # Convert to Torch Tensor and reshape\n","                x = torch.Tensor(x).view(1, 3, 32, 32)  # Reshape to [1, 3, 32, 32]\n","\n","                # Forward pass\n","                pred = model(x)\n","                confidence = F.softmax(pred, dim=1).numpy().reshape(-1)\n","\n","                # Find the highest confidence score and its corresponding class index\n","                max_confidence = np.max(confidence)          # **New Line**\n","                max_class = np.argmax(confidence)            # **New Line**\n","\n","\n","                # Print the highest confidence and corresponding class\n","                print('\\nData {}'.format(i))\n","\n","                confidence_sorted = np.sort(confidence)\n","                print(confidence_sorted)\n","\n","                print(f\"Highest Confidence: {max_confidence:.4f}\")  # **Modified Line**\n","            except FileNotFoundError:\n","                print(f\"File not found: {file_name}\")\n","            except Exception as e:\n","                print(f\"Error processing file {file_name}: {e}\")\n","\n","model = load_model(CIFAR100Net, HOME_DIR + 'exercise5/cifar100.pt')\n","\n","\n","print('\\n===================================\\n')\n","print('Confidence with train data')\n","print_confidence(model, 'train')\n","print('\\n===================================\\n')\n","\n","print('\\n===================================\\n')\n","print('Confidence with test data')\n","print_confidence(model, 'test')\n","print('\\n===================================\\n')\n"],"metadata":{"id":"4GWxuicwmEcV"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"1lOkAUD3w04g5gHVhFqYzgY-oOzQ61QMO","timestamp":1735550059836}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}